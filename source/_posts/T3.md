---
title: Task 3 (17th August 2023 )
date: 2023-08-17 
tags: Weekly tasks
domain: AI
---

# AI | Task 3
### Submission Deadline : 28-08-2023 23:59
<hr>


# Exercises


## Q1

>     Resources: 
https://www.javatpoint.com/machine-learning-random-forest-algorithm

https://www.kaggle.com/datasets/shilongzhuang/telecom-customer-churn-by-maven-analytics

### You have been provided with a dataset containing information about various houses and their corresponding prices.(House price prediction dataset can be provided)

### Data Exploration:

- Load and explore the dataset. How many instances and features are present? Are there any missing values?

- What is the distribution of the target variable (price)? Are there any outliers?

### Data Preprocessing:

 - Handle any missing values and perform necessary data preprocessing steps.

- Convert categorical variables (e.g., presence of a garage) into numerical format using appropriate encoding techniques.

### Model Building:
Build a basic linear regression model using the provided features to predict the housing prices. Split the dataset into training and testing sets (e.g., 80-20 split).
#### Model Analysis:
- Interpret the coefficients of the linear regression model. What do the coefficients represent for each feature?
- Compute the model's R-squared value. What does this value indicate about the goodness of fit?

#### Predictions and Interpretation:
- Make predictions on the testing set using the trained linear regression model.
- Select a few instances from the testing set and explain how the model's coefficients influence the predicted prices for those instances.
- Identify instances where the model's predictions have a large error compared to the actual prices. What could be the potential reasons for these errors?

#### Model Improvement:
- Are there any additional features you would consider adding to the model to potentially improve its performance?
- Discuss one or two alternative regression algorithms that could be used instead of linear regression for this problem.

Summarize your findings from building and analyzing the linear regression model for predicting housing prices. Reflect on the model's strengths and limitations.

### Model Validation

- Split Your Data

     Use the `train_test_split` function to split up your data.

     Give it the argument `random_state=1` so the `check` functions know what to expect when verifying your code.

     Recall, your features are loaded in the DataFrame *X* and your target is loaded in *y*.

- Specify and Fit the Model
Create a DecisionTreeRegressor model and fit it to the relevant data. Set random_state to 1 again when creating the model.
- Make Predictions with Validation data
- Calculate the Mean Absolute Error in Validation Data




## Q2
### You have been provided with a dataset containing information about customers of a telecommunications company and whether they have churned (1) or not (0). (Customer Churn Prediction)

#### Data Exploration:
- Load and explore the dataset. How many instances and features are present? Are there any missing values?
- What is the distribution of the target variable (churn)? Is the dataset balanced or imbalanced?

#### Data Preprocessing:
- Handle any missing values and perform necessary data preprocessing steps.
- Convert categorical variables (e.g., contract_type, internet_service) into numerical format using appropriate encoding techniques.

#### Model Building:
Build a logistic regression model to predict customer churn based on the provided features. Split the dataset into training and testing sets (e.g., 80-20 split).

- Model Analysis:
  -  Interpret the coefficients of the logistic regression model. How do the coefficients relate to the odds of customer churn for each feature?
  -  Calculate the accuracy, precision, recall, and F1-score of the model on the testing set. Interpret these metrics in the context of customer churn prediction.

- Predictions and Interpretation:
   - Make predictions on the testing set using the trained logistic regression model.
   - Select a few instances from the testing set and explain how the model's coefficients and predicted probabilities contribute to the decision of whether a customer will churn or not.

#### Feature Importance and Business Insights:
-  Rank the features based on their importance in predicting customer churn. How can these insights help the telecommunications company in retaining customers?
-  Which customer segments are more likely to churn based on the model's predictions? Suggest targeted strategies to reduce churn for these segments.

#### Model Comparison:
- Compare the logistic regression model's performance with an alternative classification algorithm, such as decision trees or random forests. Discuss the advantages and disadvantages of each approach for this specific problem.

- Summarize your findings from building and analyzing the logistic regression model for customer churn prediction. Reflect on the model's potential applications and limitations in real-world scenarios.

---------------------------------------------------------------------------------------------

>     Documentation: 
https://www.javatpoint.com/machine-learning-random-forest-algorithm
    
>     Video:  
https://www.youtube.com/watch?v=3LQI-w7-FuE

**For this task use this dataset:**
https://www.kaggle.com/datasets/elikplim/car-evaluation-data-set

**Task to be done:**
- import the libraries
- Import the dataset.
- Put Feature Variable to X and Target variable to y
- Train-Test-Split
- import RandomForestClassifier and fit the data.
- visualize the dataset
- predict accuracy .
### **Overfiting and Underfiting Machine Larning Model**
**For more information on underfiting and overfiting of machine larning models you can go through :**
> **Documentation:**

https://www.superannotate.com/blog/overfitting-and-underfitting-in-machine-learning

> **Video Link:**

https://www.youtube.com/watch?v=W-0-u6XVbE4

**For this task dataset to be used is:**
https://www.kaggle.com/datasets/uciml/mushroom-classification
-  Load the Dataset and perform basic pre processing.
- Remove the NULL and DUPLICATE values
- Perform Encoding on categorical data
- Perform EDA and Plot the CORRELATION between different features of the dataset
- Use Multiple models to check for the best mode among them ( USE ATLEAST 4 DIFFERENT MODELS)
